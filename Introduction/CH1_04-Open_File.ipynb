{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "<font size = \"5\"> **Chapter 1: [Introduction](CH1_00-Introduction.ipynb)** </font>\n",
    "\n",
    "\n",
    "<hr style=\"height:1px;border-top:4px solid #FF8200\" />\n",
    "\n",
    "# Open DM3 Images, Spectra, Spectrum-Images and  Image-Stacks with pyNSID \n",
    "\n",
    "[Download](https://raw.githubusercontent.com/gduscher/MSE672-Introduction-to-TEM//main/Introduction/CH1_04-Open_File.ipynb)\n",
    " \n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](\n",
    "    https://colab.research.google.com/github/gduscher/MSE672-Introduction-to-TEM/blob/main/Introduction/CH1_04-Open_File.ipynb)\n",
    "\n",
    "\n",
    "part of \n",
    "\n",
    "<font size = \"5\"> **[MSE672:  Introduction to Transmission Electron Microscopy](../_MSE672_Intro_TEM.ipynb)**</font>\n",
    "\n",
    "by Gerd Duscher, Spring 2022\n",
    "\n",
    "Microscopy Facilities<br>\n",
    "Institute of Advanced Materials & Manufacturing<br>\n",
    "Materials Science & Engineering<br>\n",
    "The University of Tennessee, Knoxville\n",
    "\n",
    "Background and methods to analysis and quantification of data acquired with transmission electron microscopes.\n",
    "\n",
    "---\n",
    "Reading a dm file and translating the data in a **[pyNSID](https://pycroscopy.github.io/pyNSID/)** style hf5py file to be compatible with  the **[pycroscopy](https://pycroscopy.github.io/pycroscopy/)** package.\n",
    "\n",
    "Because, many other packages and programs for TEM data manipulation are based on the ``hdf5`` file-formats it is relatively easy to convert back and forward between them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Import packages for figures and\n",
    "### Check Installed Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from pkg_resources import get_distribution, DistributionNotFound\n",
    "\n",
    "def test_package(package_name):\n",
    "    \"\"\"Test if package exists and returns version or -1\"\"\"\n",
    "    try:\n",
    "        version = get_distribution(package_name).version\n",
    "    except (DistributionNotFound, ImportError):\n",
    "        version = '-1'\n",
    "    return version\n",
    "\n",
    "if test_package('pyTEMlib') < '0.2021.12.1':\n",
    "        print('installing pyTEMlib')\n",
    "        !{sys.executable} -m pip install  --upgrade pyTEMlib -q\n",
    "# ------------------------------\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the plotting and figure packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "pyTEM version:  0.2021.12.1\n"
     ]
    }
   ],
   "source": [
    "%pylab --no-import-all notebook\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../pyTEMlib')\n",
    "import pyTEMlib\n",
    "import pyTEMlib.file_tools  as ft     # File input/ output library\n",
    "\n",
    "import sidpy\n",
    "import pyNSID\n",
    "import h5py\n",
    "\n",
    "# For archiving reasons it is a good idea to print the version numbers out at this point\n",
    "print('pyTEM version: ',pyTEMlib.__version__)\n",
    "__notebook__='CH1_04-Reading_File'\n",
    "__notebook_version__='2021_12_14'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Open a file \n",
    "\n",
    "This function opens a hfd5 file in the pyNSID style which enables you to keep track of your data analysis.\n",
    "\n",
    "Please see the **[Installation](CH1_02-Prerequisites.ipynb#TEM-Library)** notebook for installation.\n",
    "\n",
    "We want to consolidate files into one dataset that belongs together.  For example a spectrum image dataset consists of: \n",
    "* Survey image, \n",
    "* EELS spectra \n",
    "* Z-contrast image acquired simultaneously with the spectra.\n",
    "\n",
    "\n",
    "So load the top dataset first in the above example the survey image.\n",
    "\n",
    "Please note that the plotting routine of ``matplotlib`` was introduced in **[Matplotlib and Numpy for Micrographs](CH1_03-Data_Representation.ipynb)** notebook.\n",
    "\n",
    "**Use the file p1-3hr.dm3 from TEM_data directory for a practice run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Select(description='Select file:', layout=Layout(width='70%'), options=('.',), rows=10, value='.')",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7f2f613ded7d4509966ce3dafac3c38f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------ Input ------- #\n",
    "load_example = True\n",
    "# -------------------- #\n",
    "\n",
    "# Open file widget and select file which will be opened in code cell below\n",
    "if not load_example:\n",
    "    drive_directory = ft.get_last_path()\n",
    "    file_widget = ft.FileWidget(drive_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot overwrite file. Using:  p1_3_hr3-13.hf5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Failed to clean: [[0, 0, 0], [257, 257, 257], [514, 514, 514], [771, 771, 771], [1028, 1028, 1028], [1285, 1285, 1285], [1542, 1542, 1542], [1799, 1799, 1799], [2056, 2056, 2056], [2313, 2313, 2313], [2570, 2570, 2570], [2827, 2827, 2827], [3084, 3084, 3084], [3341, 3341, 3341], [3598, 3598, 3598], [3855, 3855, 3855], [4112, 4112, 4112], [4369, 4369, 4369], [4626, 4626, 4626], [4883, 4883, 4883], [5140, 5140, 5140], [5397, 5397, 5397], [5654, 5654, 5654], [5911, 5911, 5911], [6168, 6168, 6168], [6425, 6425, 6425], [6682, 6682, 6682], [6939, 6939, 6939], [7196, 7196, 7196], [7453, 7453, 7453], [7710, 7710, 7710], [7967, 7967, 7967], [8224, 8224, 8224], [8481, 8481, 8481], [8738, 8738, 8738], [8995, 8995, 8995], [9252, 9252, 9252], [9509, 9509, 9509], [9766, 9766, 9766], [10023, 10023, 10023], [10280, 10280, 10280], [10537, 10537, 10537], [10794, 10794, 10794], [11051, 11051, 11051], [11308, 11308, 11308], [11565, 11565, 11565], [11822, 11822, 11822], [12079, 12079, 12079], [12336, 12336, 12336], [12593, 12593, 12593], [12850, 12850, 12850], [13107, 13107, 13107], [13364, 13364, 13364], [13621, 13621, 13621], [13878, 13878, 13878], [14135, 14135, 14135], [14392, 14392, 14392], [14649, 14649, 14649], [14906, 14906, 14906], [15163, 15163, 15163], [15420, 15420, 15420], [15677, 15677, 15677], [15934, 15934, 15934], [16191, 16191, 16191], [16448, 16448, 16448], [16705, 16705, 16705], [16962, 16962, 16962], [17219, 17219, 17219], [17476, 17476, 17476], [17733, 17733, 17733], [17990, 17990, 17990], [18247, 18247, 18247], [18504, 18504, 18504], [18761, 18761, 18761], [19018, 19018, 19018], [19275, 19275, 19275], [19532, 19532, 19532], [19789, 19789, 19789], [20046, 20046, 20046], [20303, 20303, 20303], [20560, 20560, 20560], [20817, 20817, 20817], [21074, 21074, 21074], [21331, 21331, 21331], [21588, 21588, 21588], [21845, 21845, 21845], [22102, 22102, 22102], [22359, 22359, 22359], [22616, 22616, 22616], [22873, 22873, 22873], [23130, 23130, 23130], [23387, 23387, 23387], [23644, 23644, 23644], [23901, 23901, 23901], [24158, 24158, 24158], [24415, 24415, 24415], [24672, 24672, 24672], [24929, 24929, 24929], [25186, 25186, 25186], [25443, 25443, 25443], [25700, 25700, 25700], [25957, 25957, 25957], [26214, 26214, 26214], [26471, 26471, 26471], [26728, 26728, 26728], [26985, 26985, 26985], [27242, 27242, 27242], [27499, 27499, 27499], [27756, 27756, 27756], [28013, 28013, 28013], [28270, 28270, 28270], [28527, 28527, 28527], [28784, 28784, 28784], [29041, 29041, 29041], [29298, 29298, 29298], [29555, 29555, 29555], [29812, 29812, 29812], [30069, 30069, 30069], [30326, 30326, 30326], [30583, 30583, 30583], [30840, 30840, 30840], [31097, 31097, 31097], [31354, 31354, 31354], [31611, 31611, 31611], [31868, 31868, 31868], [32125, 32125, 32125], [32382, 32382, 32382], [32639, 32639, 32639], [-32640, -32640, -32640], [-32383, -32383, -32383], [-32126, -32126, -32126], [-31869, -31869, -31869], [-31612, -31612, -31612], [-31355, -31355, -31355], [-31098, -31098, -31098], [-30841, -30841, -30841], [-30584, -30584, -30584], [-30327, -30327, -30327], [-30070, -30070, -30070], [-29813, -29813, -29813], [-29556, -29556, -29556], [-29299, -29299, -29299], [-29042, -29042, -29042], [-28785, -28785, -28785], [-28528, -28528, -28528], [-28271, -28271, -28271], [-28014, -28014, -28014], [-27757, -27757, -27757], [-27500, -27500, -27500], [-27243, -27243, -27243], [-26986, -26986, -26986], [-26729, -26729, -26729], [-26472, -26472, -26472], [-26215, -26215, -26215], [-25958, -25958, -25958], [-25701, -25701, -25701], [-25444, -25444, -25444], [-25187, -25187, -25187], [-24930, -24930, -24930], [-24673, -24673, -24673], [-24416, -24416, -24416], [-24159, -24159, -24159], [-23902, -23902, -23902], [-23645, -23645, -23645], [-23388, -23388, -23388], [-23131, -23131, -23131], [-22874, -22874, -22874], [-22617, -22617, -22617], [-22360, -22360, -22360], [-22103, -22103, -22103], [-21846, -21846, -21846], [-21589, -21589, -21589], [-21332, -21332, -21332], [-21075, -21075, -21075], [-20818, -20818, -20818], [-20561, -20561, -20561], [-20304, -20304, -20304], [-20047, -20047, -20047], [-19790, -19790, -19790], [-19533, -19533, -19533], [-19276, -19276, -19276], [-19019, -19019, -19019], [-18762, -18762, -18762], [-18505, -18505, -18505], [-18248, -18248, -18248], [-17991, -17991, -17991], [-17734, -17734, -17734], [-17477, -17477, -17477], [-17220, -17220, -17220], [-16963, -16963, -16963], [-16706, -16706, -16706], [-16449, -16449, -16449], [-16192, -16192, -16192], [-15935, -15935, -15935], [-15678, -15678, -15678], [-15421, -15421, -15421], [-15164, -15164, -15164], [-14907, -14907, -14907], [-14650, -14650, -14650], [-14393, -14393, -14393], [-14136, -14136, -14136], [-13879, -13879, -13879], [-13622, -13622, -13622], [-13365, -13365, -13365], [-13108, -13108, -13108], [-12851, -12851, -12851], [-12594, -12594, -12594], [-12337, -12337, -12337], [-12080, -12080, -12080], [-11823, -11823, -11823], [-11566, -11566, -11566], [-11309, -11309, -11309], [-11052, -11052, -11052], [-10795, -10795, -10795], [-10538, -10538, -10538], [-10281, -10281, -10281], [-10024, -10024, -10024], [-9767, -9767, -9767], [-9510, -9510, -9510], [-9253, -9253, -9253], [-8996, -8996, -8996], [-8739, -8739, -8739], [-8482, -8482, -8482], [-8225, -8225, -8225], [-7968, -7968, -7968], [-7711, -7711, -7711], [-7454, -7454, -7454], [-7197, -7197, -7197], [-6940, -6940, -6940], [-6683, -6683, -6683], [-6426, -6426, -6426], [-6169, -6169, -6169], [-5912, -5912, -5912], [-5655, -5655, -5655], [-5398, -5398, -5398], [-5141, -5141, -5141], [-4884, -4884, -4884], [-4627, -4627, -4627], [-4370, -4370, -4370], [-4113, -4113, -4113], [-3856, -3856, -3856], [-3599, -3599, -3599], [-3342, -3342, -3342], [-3085, -3085, -3085], [-2828, -2828, -2828], [-2571, -2571, -2571], [-2314, -2314, -2314], [-2057, -2057, -2057], [-1800, -1800, -1800], [-1543, -1543, -1543], [-1286, -1286, -1286], [-1029, -1029, -1029], [-772, -772, -772], [-515, -515, -515], [-258, -258, -258], [-1, -1, -1]]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m~/anaconda3/envs/p39/lib/python3.9/site-packages/sidpy/base/string_utils.py\u001B[0m in \u001B[0;36mclean_string_att\u001B[0;34m(att_val)\u001B[0m\n\u001B[1;32m    342\u001B[0m                                              Number)):\n\u001B[0;32m--> 343\u001B[0;31m                         raise TypeError('Provided object was a list or tuple '\n\u001B[0m\u001B[1;32m    344\u001B[0m                                          \u001B[0;34m'whose element was not a string or '\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: Provided object was a list or tuple whose element was not a string or number but was of type: <class 'list'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_51284/1229845160.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      9\u001B[0m     \u001B[0mfile_name\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfile_widget\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfile_name\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m \u001B[0mmain_dataset\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mft\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mopen_file\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfile_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m \u001B[0;31m#current_channel = main_dataset.h5_dataset.parent.parent\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/github/MSE672-Introduction-to-TEM/Introduction/../../pyTEMlib/pyTEMlib/file_tools.py\u001B[0m in \u001B[0;36mopen_file\u001B[0;34m(filename, h5_group, write_hdf_file)\u001B[0m\n\u001B[1;32m    621\u001B[0m                 \u001B[0;31m# dset.axes = dset._axes\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    622\u001B[0m                 \u001B[0;31m# dset.attrs = {}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 623\u001B[0;31m                 \u001B[0mh5_dataset\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpyNSID\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhdf_io\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwrite_nsid_dataset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdset\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mh5_group\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    624\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    625\u001B[0m                 \u001B[0;31m# dset.original_metadata = nest_dict(dset.original_metadata)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/p39/lib/python3.9/site-packages/pyNSID/io/hdf_io.py\u001B[0m in \u001B[0;36mwrite_nsid_dataset\u001B[0;34m(dataset, h5_group, main_data_name, verbose, **kwargs)\u001B[0m\n\u001B[1;32m    185\u001B[0m                 print('Writing attributes from property: {} of the '\n\u001B[1;32m    186\u001B[0m                       'sidpy.Dataset'.format(attr_name))\n\u001B[0;32m--> 187\u001B[0;31m             \u001B[0mwrite_dict_to_h5_group\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mh5_group\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mattr_val\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mattr_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    188\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    189\u001B[0m     \u001B[0;31m# This will attach the dimensions\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/p39/lib/python3.9/site-packages/sidpy/hdf/hdf_utils.py\u001B[0m in \u001B[0;36mwrite_dict_to_h5_group\u001B[0;34m(h5_group, metadata, group_name)\u001B[0m\n\u001B[1;32m    792\u001B[0m     \u001B[0mh5_md_group\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mh5_group\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcreate_group\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgroup_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    793\u001B[0m     \u001B[0;31m# flat_dict = flatten_dict(metadata)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 794\u001B[0;31m     \u001B[0mwrite_simple_attrs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mh5_md_group\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmetadata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    795\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mh5_md_group\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    796\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/p39/lib/python3.9/site-packages/sidpy/hdf/hdf_utils.py\u001B[0m in \u001B[0;36mwrite_simple_attrs\u001B[0;34m(h5_obj, attrs, force_to_str, verbose)\u001B[0m\n\u001B[1;32m    424\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    425\u001B[0m                 \u001B[0mnew_object\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mh5_obj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcreate_group\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 426\u001B[0;31m                 \u001B[0mwrite_simple_attrs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnew_object\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mforce_to_str\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    427\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    428\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/p39/lib/python3.9/site-packages/sidpy/hdf/hdf_utils.py\u001B[0m in \u001B[0;36mwrite_simple_attrs\u001B[0;34m(h5_obj, attrs, force_to_str, verbose)\u001B[0m\n\u001B[1;32m    424\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    425\u001B[0m                 \u001B[0mnew_object\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mh5_obj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcreate_group\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 426\u001B[0;31m                 \u001B[0mwrite_simple_attrs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnew_object\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mforce_to_str\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    427\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    428\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/p39/lib/python3.9/site-packages/sidpy/hdf/hdf_utils.py\u001B[0m in \u001B[0;36mwrite_simple_attrs\u001B[0;34m(h5_obj, attrs, force_to_str, verbose)\u001B[0m\n\u001B[1;32m    424\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    425\u001B[0m                 \u001B[0mnew_object\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mh5_obj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcreate_group\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 426\u001B[0;31m                 \u001B[0mwrite_simple_attrs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnew_object\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mforce_to_str\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    427\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    428\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/p39/lib/python3.9/site-packages/sidpy/hdf/hdf_utils.py\u001B[0m in \u001B[0;36mwrite_simple_attrs\u001B[0;34m(h5_obj, attrs, force_to_str, verbose)\u001B[0m\n\u001B[1;32m    432\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    433\u001B[0m                 \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mval\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 434\u001B[0;31m             \u001B[0mclean_val\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mclean_string_att\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mval\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    435\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    436\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/p39/lib/python3.9/site-packages/sidpy/base/string_utils.py\u001B[0m in \u001B[0;36mclean_string_att\u001B[0;34m(att_val)\u001B[0m\n\u001B[1;32m    349\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0matt_val\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    350\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 351\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Failed to clean: {}'\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0matt_val\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    352\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    353\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: Failed to clean: [[0, 0, 0], [257, 257, 257], [514, 514, 514], [771, 771, 771], [1028, 1028, 1028], [1285, 1285, 1285], [1542, 1542, 1542], [1799, 1799, 1799], [2056, 2056, 2056], [2313, 2313, 2313], [2570, 2570, 2570], [2827, 2827, 2827], [3084, 3084, 3084], [3341, 3341, 3341], [3598, 3598, 3598], [3855, 3855, 3855], [4112, 4112, 4112], [4369, 4369, 4369], [4626, 4626, 4626], [4883, 4883, 4883], [5140, 5140, 5140], [5397, 5397, 5397], [5654, 5654, 5654], [5911, 5911, 5911], [6168, 6168, 6168], [6425, 6425, 6425], [6682, 6682, 6682], [6939, 6939, 6939], [7196, 7196, 7196], [7453, 7453, 7453], [7710, 7710, 7710], [7967, 7967, 7967], [8224, 8224, 8224], [8481, 8481, 8481], [8738, 8738, 8738], [8995, 8995, 8995], [9252, 9252, 9252], [9509, 9509, 9509], [9766, 9766, 9766], [10023, 10023, 10023], [10280, 10280, 10280], [10537, 10537, 10537], [10794, 10794, 10794], [11051, 11051, 11051], [11308, 11308, 11308], [11565, 11565, 11565], [11822, 11822, 11822], [12079, 12079, 12079], [12336, 12336, 12336], [12593, 12593, 12593], [12850, 12850, 12850], [13107, 13107, 13107], [13364, 13364, 13364], [13621, 13621, 13621], [13878, 13878, 13878], [14135, 14135, 14135], [14392, 14392, 14392], [14649, 14649, 14649], [14906, 14906, 14906], [15163, 15163, 15163], [15420, 15420, 15420], [15677, 15677, 15677], [15934, 15934, 15934], [16191, 16191, 16191], [16448, 16448, 16448], [16705, 16705, 16705], [16962, 16962, 16962], [17219, 17219, 17219], [17476, 17476, 17476], [17733, 17733, 17733], [17990, 17990, 17990], [18247, 18247, 18247], [18504, 18504, 18504], [18761, 18761, 18761], [19018, 19018, 19018], [19275, 19275, 19275], [19532, 19532, 19532], [19789, 19789, 19789], [20046, 20046, 20046], [20303, 20303, 20303], [20560, 20560, 20560], [20817, 20817, 20817], [21074, 21074, 21074], [21331, 21331, 21331], [21588, 21588, 21588], [21845, 21845, 21845], [22102, 22102, 22102], [22359, 22359, 22359], [22616, 22616, 22616], [22873, 22873, 22873], [23130, 23130, 23130], [23387, 23387, 23387], [23644, 23644, 23644], [23901, 23901, 23901], [24158, 24158, 24158], [24415, 24415, 24415], [24672, 24672, 24672], [24929, 24929, 24929], [25186, 25186, 25186], [25443, 25443, 25443], [25700, 25700, 25700], [25957, 25957, 25957], [26214, 26214, 26214], [26471, 26471, 26471], [26728, 26728, 26728], [26985, 26985, 26985], [27242, 27242, 27242], [27499, 27499, 27499], [27756, 27756, 27756], [28013, 28013, 28013], [28270, 28270, 28270], [28527, 28527, 28527], [28784, 28784, 28784], [29041, 29041, 29041], [29298, 29298, 29298], [29555, 29555, 29555], [29812, 29812, 29812], [30069, 30069, 30069], [30326, 30326, 30326], [30583, 30583, 30583], [30840, 30840, 30840], [31097, 31097, 31097], [31354, 31354, 31354], [31611, 31611, 31611], [31868, 31868, 31868], [32125, 32125, 32125], [32382, 32382, 32382], [32639, 32639, 32639], [-32640, -32640, -32640], [-32383, -32383, -32383], [-32126, -32126, -32126], [-31869, -31869, -31869], [-31612, -31612, -31612], [-31355, -31355, -31355], [-31098, -31098, -31098], [-30841, -30841, -30841], [-30584, -30584, -30584], [-30327, -30327, -30327], [-30070, -30070, -30070], [-29813, -29813, -29813], [-29556, -29556, -29556], [-29299, -29299, -29299], [-29042, -29042, -29042], [-28785, -28785, -28785], [-28528, -28528, -28528], [-28271, -28271, -28271], [-28014, -28014, -28014], [-27757, -27757, -27757], [-27500, -27500, -27500], [-27243, -27243, -27243], [-26986, -26986, -26986], [-26729, -26729, -26729], [-26472, -26472, -26472], [-26215, -26215, -26215], [-25958, -25958, -25958], [-25701, -25701, -25701], [-25444, -25444, -25444], [-25187, -25187, -25187], [-24930, -24930, -24930], [-24673, -24673, -24673], [-24416, -24416, -24416], [-24159, -24159, -24159], [-23902, -23902, -23902], [-23645, -23645, -23645], [-23388, -23388, -23388], [-23131, -23131, -23131], [-22874, -22874, -22874], [-22617, -22617, -22617], [-22360, -22360, -22360], [-22103, -22103, -22103], [-21846, -21846, -21846], [-21589, -21589, -21589], [-21332, -21332, -21332], [-21075, -21075, -21075], [-20818, -20818, -20818], [-20561, -20561, -20561], [-20304, -20304, -20304], [-20047, -20047, -20047], [-19790, -19790, -19790], [-19533, -19533, -19533], [-19276, -19276, -19276], [-19019, -19019, -19019], [-18762, -18762, -18762], [-18505, -18505, -18505], [-18248, -18248, -18248], [-17991, -17991, -17991], [-17734, -17734, -17734], [-17477, -17477, -17477], [-17220, -17220, -17220], [-16963, -16963, -16963], [-16706, -16706, -16706], [-16449, -16449, -16449], [-16192, -16192, -16192], [-15935, -15935, -15935], [-15678, -15678, -15678], [-15421, -15421, -15421], [-15164, -15164, -15164], [-14907, -14907, -14907], [-14650, -14650, -14650], [-14393, -14393, -14393], [-14136, -14136, -14136], [-13879, -13879, -13879], [-13622, -13622, -13622], [-13365, -13365, -13365], [-13108, -13108, -13108], [-12851, -12851, -12851], [-12594, -12594, -12594], [-12337, -12337, -12337], [-12080, -12080, -12080], [-11823, -11823, -11823], [-11566, -11566, -11566], [-11309, -11309, -11309], [-11052, -11052, -11052], [-10795, -10795, -10795], [-10538, -10538, -10538], [-10281, -10281, -10281], [-10024, -10024, -10024], [-9767, -9767, -9767], [-9510, -9510, -9510], [-9253, -9253, -9253], [-8996, -8996, -8996], [-8739, -8739, -8739], [-8482, -8482, -8482], [-8225, -8225, -8225], [-7968, -7968, -7968], [-7711, -7711, -7711], [-7454, -7454, -7454], [-7197, -7197, -7197], [-6940, -6940, -6940], [-6683, -6683, -6683], [-6426, -6426, -6426], [-6169, -6169, -6169], [-5912, -5912, -5912], [-5655, -5655, -5655], [-5398, -5398, -5398], [-5141, -5141, -5141], [-4884, -4884, -4884], [-4627, -4627, -4627], [-4370, -4370, -4370], [-4113, -4113, -4113], [-3856, -3856, -3856], [-3599, -3599, -3599], [-3342, -3342, -3342], [-3085, -3085, -3085], [-2828, -2828, -2828], [-2571, -2571, -2571], [-2314, -2314, -2314], [-2057, -2057, -2057], [-1800, -1800, -1800], [-1543, -1543, -1543], [-1286, -1286, -1286], [-1029, -1029, -1029], [-772, -772, -772], [-515, -515, -515], [-258, -258, -258], [-1, -1, -1]]"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    main_dataset.h5_dataset.file.close()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "if load_example:\n",
    "    file_name = '../example_data/p1_3_hr3.dm3'\n",
    "else:\n",
    "    file_name = file_widget.file_name\n",
    "\n",
    "main_dataset = ft.open_file(file_name)\n",
    "#current_channel = main_dataset.h5_dataset.parent.parent\n",
    "\n",
    "main_dataset.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../example_data/p1_3_hr3.dm3\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "../example_data/p1_3_hr3.dm3 does not exist",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_51284/3665273864.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfile_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mft\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mopen_file\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfile_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/Documents/github/MSE672-Introduction-to-TEM/Introduction/../../pyTEMlib/pyTEMlib/file_tools.py\u001B[0m in \u001B[0;36mopen_file\u001B[0;34m(filename, h5_group, write_hdf_file)\u001B[0m\n\u001B[1;32m    588\u001B[0m         \u001B[0;31m# tags = open_file(filename)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    589\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mextension\u001B[0m \u001B[0;32min\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m'.dm3'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'.dm4'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 590\u001B[0;31m             \u001B[0mreader\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mSciFiReaders\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDM3Reader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    591\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m   \u001B[0;31m# extension in ['.ndata', '.h5']:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    592\u001B[0m             \u001B[0mreader\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mSciFiReaders\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mNionReader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/p39/lib/python3.9/site-packages/SciFiReaders/readers/microscopy/em/tem/dm_reader.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, file_path, verbose)\u001B[0m\n\u001B[1;32m    493\u001B[0m         warnings.warn(DeprecationWarning('Use DMReader class instead marking\\n '\n\u001B[1;32m    494\u001B[0m                                          'Note that you can now read dm4 files too'))\n\u001B[0;32m--> 495\u001B[0;31m         \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfile_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mverbose\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/anaconda3/envs/p39/lib/python3.9/site-packages/SciFiReaders/readers/microscopy/em/tem/dm_reader.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, file_path, verbose)\u001B[0m\n\u001B[1;32m    135\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    136\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfile_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 137\u001B[0;31m         \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfile_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    138\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    139\u001B[0m         \u001B[0;31m# initialize variables ##\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/p39/lib/python3.9/site-packages/sidpy/sid/reader.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, file_path, *args, **kwargs)\u001B[0m\n\u001B[1;32m     55\u001B[0m         \u001B[0mfile_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvalidate_single_string_arg\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfile_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'file_path'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     56\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexists\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfile_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 57\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mFileNotFoundError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfile_path\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m' does not exist'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     58\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_input_file_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfile_path\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     59\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: ../example_data/p1_3_hr3.dm3 does not exist"
     ]
    }
   ],
   "source": [
    "print(file_name)\n",
    "ft.open_file(file_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structure\n",
    "\n",
    "The data themselves reside in a ``sidpy dataset`` which we name ``current_dataset``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current_dataset has additional information stored as attributes which can be accessed through their name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sidpy.Dataset of type IMAGE with:\n",
      " dask.array<generic, shape=(1024, 1024), dtype=float32, chunksize=(1024, 1024), chunktype=numpy.ndarray>\n",
      " data contains: intensity (counts)\n",
      " and Dimensions: \n",
      "y:  distance (nm) of size (1024,)\n",
      "x:  distance (nm) of size (1024,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th> Bytes </th><td> 4.19 MB </td> <td> 4.19 MB </td></tr>\n",
       "    <tr><th> Shape </th><td> (1024, 1024) </td> <td> (1024, 1024) </td></tr>\n",
       "    <tr><th> Count </th><td> 1 Tasks </td><td> 1 Chunks </td></tr>\n",
       "    <tr><th> Type </th><td> float32 </td><td> numpy.ndarray </td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</td>\n",
       "<td>\n",
       "<svg width=\"170\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"120\" x2=\"120\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,120.0 0.0,120.0\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"140.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1024</text>\n",
       "  <text x=\"140.000000\" y=\"60.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,140.000000,60.000000)\">1024</text>\n",
       "</svg>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "sidpy.Dataset of type IMAGE with:\n",
       " dask.array<generic, shape=(1024, 1024), dtype=float32, chunksize=(1024, 1024), chunktype=numpy.ndarray>\n",
       " data contains: intensity (counts)\n",
       " and Dimensions: \n",
       "y:  distance (nm) of size (1024,)\n",
       "x:  distance (nm) of size (1024,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(main_dataset)\n",
    "main_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of current dataset is (2048,)\n"
     ]
    }
   ],
   "source": [
    "print(f'size of current dataset is {main_dataset.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current_dataset has additional information stored as attributes which can be accessed through their name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title:  /Measurement_000/Channel_000/SuperScan (HAADF) 45/SuperScan (HAADF) 45\n",
      "data type:  DataType.IMAGE\n"
     ]
    }
   ],
   "source": [
    "print('title: ', main_dataset.title)\n",
    "print('data type: ', main_dataset.data_type)\n",
    "main_dataset.metadata\n",
    "for key in current_channel:\n",
    "    try:\n",
    "        if key in current_channel[key]:\n",
    "            print(current_channel[key][key]['original_metadata'].attrs.keys())\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Structure\n",
    "The current_channel (like a directory in a file system) contains several groups.\n",
    "\n",
    "Below I show how to access one of those groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['SuperScan (HAADF) 45']>\n",
      "<HDF5 group \"/Measurement_000/Channel_000\" (1 members)>\n",
      "<HDF5 dataset \"SuperScan (HAADF) 45\": shape (1024, 1024), type \"<f4\">\n",
      "<HDF5 dataset \"SuperScan (HAADF) 45\": shape (1024, 1024), type \"<f4\">\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gduscher\\Anaconda3\\lib\\site-packages\\sidpy\\hdf\\hdf_utils.py:419: UserWarning: Casting attribute value: <HDF5 dataset \"SuperScan (HAADF) 45\": shape (1024, 1024), type \"<f4\"> of type: <class 'h5py._hl.dataset.Dataset'> to str\n",
      "  warn('Casting attribute value: {} of type: {} to str'\n",
      "C:\\Users\\gduscher\\Anaconda3\\lib\\site-packages\\sidpy\\hdf\\hdf_utils.py:419: UserWarning: Casting attribute value: <sidpy.viz.dataset_viz.ImageVisualizer object at 0x000001ACD68FE070> of type: <class 'sidpy.viz.dataset_viz.ImageVisualizer'> to str\n",
      "  warn('Casting attribute value: {} of type: {} to str'\n",
      "C:\\Users\\gduscher\\Anaconda3\\lib\\site-packages\\pyNSID\\io\\hdf_utils.py:351: FutureWarning: validate_h5_dimension may be removed in a future version\n",
      "  warn('validate_h5_dimension may be removed in a future version',\n"
     ]
    }
   ],
   "source": [
    "current_dataset = main_dataset\n",
    "print(current_channel.keys())\n",
    "def add_data(dataset, h5_group=None):\n",
    "    \"\"\"Write data to hdf5 file\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset: sidpy.Dataset\n",
    "        data to write to file\n",
    "    h5_group: None, sidpy.Dataset, h5py.Group, h5py.Dataset, h5py.File\n",
    "        identifier to which group the data are added (if None the dataset must have a valid h5_dataset)\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    log_group: h5py.Dataset\n",
    "        reference the dataset has been written to. (is also stored in h5_dataset attribute of sidpy.Dataset)\n",
    "    \"\"\"\n",
    "\n",
    "    if h5_group is None:\n",
    "        if isinstance(dataset.h5_dataset, h5py.Dataset):\n",
    "            h5_group = dataset.h5_dataset.parent.parent.parent\n",
    "    if isinstance(h5_group, h5py.Dataset):\n",
    "        h5_group = h5_group.parent.parent.parent\n",
    "    elif isinstance(h5_group, sidpy.Dataset):\n",
    "        h5_group = h5_group.h5_dataset.parent.parent.parent\n",
    "    elif isinstance(h5_group, h5py.File):\n",
    "        h5_group = h5_group['Measurement_000']\n",
    "        \n",
    "    if not isinstance(h5_group, h5py.Group):\n",
    "        raise TypeError('Need a valid identifier for a hdf5 group to store data in')\n",
    "\n",
    "    log_group = sidpy.hdf.prov_utils.create_indexed_group(h5_group, 'Channel_')\n",
    "    h5_dataset = pyNSID.hdf_io.write_nsid_dataset(dataset, log_group)\n",
    "    \n",
    "    if hasattr(dataset, 'meta_data'):\n",
    "        if 'analysis' in dataset.meta_data:\n",
    "            log_group['analysis'] = dataset.meta_data['analysis']\n",
    "            \n",
    "    dataset.h5_dataset = h5_dataset\n",
    "    return h5_dataset\n",
    "\n",
    "print(current_channel)\n",
    "current_dataset.metadata= {'a': 'nix', 'b': 'nada'}\n",
    "#new_data = pyNSID.hdf_io.write_results(current_channel.parent, dataset=current_dataset)\n",
    "new_data = add_data(current_dataset, h5_group=None)\n",
    "\n",
    "print(current_dataset.h5_dataset)\n",
    "print(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dict(new_data['a1_ 410s']['metadata'].attrs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important attribute in ``current_dataset`` is the ``original_metadata`` group, where all the original metadata of your file reside in the ``attributes``. This is usually a long list for ``dm3`` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 []>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dataset.h5_dataset.parent['original_metadata'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category persistent\n",
      "collection_dimension_count 0\n",
      "created 2020-03-27T14:40:59.392578\n",
      "data_dtype float32\n",
      "data_modified 2020-03-27T14:40:59.408166\n",
      "data_shape [1024 1024]\n",
      "datum_dimension_count 2\n",
      "dim-offset-0 -64.0\n",
      "dim-offset-1 -64.0\n",
      "dim-scale-0 0.125\n",
      "dim-scale-1 0.125\n",
      "dim-units-0 nm\n",
      "dim-units-1 nm\n",
      "intensity_calibration-offset 0.0\n",
      "intensity_calibration-scale 1.0\n",
      "intensity_calibration-units \n",
      "is_sequence False\n",
      "metadata-hardware_source-ac_line_sync 0\n",
      "metadata-hardware_source-autostem-ImageScanned:C1 ConstW 0.374\n",
      "metadata-hardware_source-autostem-ImageScanned:C10 6.69832e-09\n",
      "metadata-hardware_source-autostem-ImageScanned:C12.a -7.88906e-09\n",
      "metadata-hardware_source-autostem-ImageScanned:C12.b 2.49269e-08\n",
      "metadata-hardware_source-autostem-ImageScanned:C21.a -9.11232e-08\n",
      "metadata-hardware_source-autostem-ImageScanned:C21.b -8.08957e-08\n",
      "metadata-hardware_source-autostem-ImageScanned:C23.a -2.48682e-08\n",
      "metadata-hardware_source-autostem-ImageScanned:C23.b -7.40319e-08\n",
      "metadata-hardware_source-autostem-ImageScanned:C30 4.83149e-07\n",
      "metadata-hardware_source-autostem-ImageScanned:C32.a 2.59108e-06\n",
      "metadata-hardware_source-autostem-ImageScanned:C32.b -5.2936e-06\n",
      "metadata-hardware_source-autostem-ImageScanned:C34.a -2.13238e-07\n",
      "metadata-hardware_source-autostem-ImageScanned:C34.b 1.72123e-06\n",
      "metadata-hardware_source-autostem-ImageScanned:C41.a 0.000300423\n",
      "metadata-hardware_source-autostem-ImageScanned:C41.b 7.99391e-05\n",
      "metadata-hardware_source-autostem-ImageScanned:C43.a -9.56357e-06\n",
      "metadata-hardware_source-autostem-ImageScanned:C43.b 6.84714e-05\n",
      "metadata-hardware_source-autostem-ImageScanned:C45.a -0.000112058\n",
      "metadata-hardware_source-autostem-ImageScanned:C45.b 6.08676e-05\n",
      "metadata-hardware_source-autostem-ImageScanned:C50 0.00159257\n",
      "metadata-hardware_source-autostem-ImageScanned:C52.a -0.00765066\n",
      "metadata-hardware_source-autostem-ImageScanned:C52.b 0.00922618\n",
      "metadata-hardware_source-autostem-ImageScanned:C54.a -0.00334345\n",
      "metadata-hardware_source-autostem-ImageScanned:C54.b 0.00236297\n",
      "metadata-hardware_source-autostem-ImageScanned:C56.a -0.00116595\n",
      "metadata-hardware_source-autostem-ImageScanned:C56.b 0.0010319\n",
      "metadata-hardware_source-autostem-ImageScanned:EHT 100000.0\n",
      "metadata-hardware_source-autostem-ImageScanned:PMTBF2_gain 2048.0\n",
      "metadata-hardware_source-autostem-ImageScanned:PMTBF_gain 16777200.0\n",
      "metadata-hardware_source-autostem-ImageScanned:PMTDF_gain 67108900.0\n",
      "metadata-hardware_source-autostem-ImageScanned:S_EELS 0.0\n",
      "metadata-hardware_source-autostem-ImageScanned:StageOutA 0.0\n",
      "metadata-hardware_source-autostem-ImageScanned:StageOutB 0.0\n",
      "metadata-hardware_source-autostem-ImageScanned:StageOutX 2.88666e-05\n",
      "metadata-hardware_source-autostem-ImageScanned:StageOutY -0.000143388\n",
      "metadata-hardware_source-autostem-ImageScanned:StageOutZ 6.97154e-05\n",
      "metadata-hardware_source-autostem-MagBoard 0 DAC 0 0.0\n",
      "metadata-hardware_source-autostem-MagBoard 0 DAC 1 0.0\n",
      "metadata-hardware_source-autostem-MagBoard 0 DAC 10 27181.0\n",
      "metadata-hardware_source-autostem-MagBoard 0 DAC 11 51344.0\n",
      "metadata-hardware_source-autostem-MagBoard 0 DAC 2 0.0\n",
      "metadata-hardware_source-autostem-MagBoard 0 DAC 3 0.0\n",
      "metadata-hardware_source-autostem-MagBoard 0 DAC 4 28755.0\n",
      "metadata-hardware_source-autostem-MagBoard 0 DAC 5 49239.0\n",
      "metadata-hardware_source-autostem-MagBoard 0 DAC 6 487.0\n",
      "metadata-hardware_source-autostem-MagBoard 0 DAC 7 3.0\n",
      "metadata-hardware_source-autostem-MagBoard 0 DAC 8 422.0\n",
      "metadata-hardware_source-autostem-MagBoard 0 DAC 9 64806.0\n",
      "metadata-hardware_source-autostem-MagBoard 0 Relay 352.0\n",
      "metadata-hardware_source-autostem-MagBoard 1 DAC 0 0.0\n",
      "metadata-hardware_source-autostem-MagBoard 1 DAC 1 0.0\n",
      "metadata-hardware_source-autostem-MagBoard 1 DAC 10 0.0\n",
      "metadata-hardware_source-autostem-MagBoard 1 DAC 11 0.0\n",
      "metadata-hardware_source-autostem-MagBoard 1 DAC 2 0.0\n",
      "metadata-hardware_source-autostem-MagBoard 1 DAC 3 0.0\n",
      "metadata-hardware_source-autostem-MagBoard 1 DAC 4 0.0\n",
      "metadata-hardware_source-autostem-MagBoard 1 DAC 5 0.0\n",
      "metadata-hardware_source-autostem-MagBoard 1 DAC 6 0.0\n",
      "metadata-hardware_source-autostem-MagBoard 1 DAC 7 0.0\n",
      "metadata-hardware_source-autostem-MagBoard 1 DAC 8 0.0\n",
      "metadata-hardware_source-autostem-MagBoard 1 DAC 9 0.0\n",
      "metadata-hardware_source-autostem-MagBoard 1 Relay 352.0\n",
      "metadata-hardware_source-autostem-calibration_style space\n",
      "metadata-hardware_source-autostem-channel_id 0.0\n",
      "metadata-hardware_source-autostem-defocus_m 6.698324762443076e-09\n",
      "metadata-hardware_source-autostem-flyback_time_us 413.833333333333\n",
      "metadata-hardware_source-autostem-high_tension_v 100000.0\n",
      "metadata-hardware_source-autostem-line_time_us 16712.5\n",
      "metadata-hardware_source-autostem-pixels_x 1024.0\n",
      "metadata-hardware_source-autostem-pixels_y 1024.0\n",
      "metadata-hardware_source-autostem-requested_pixel_time_us 15.9999999596039\n",
      "metadata-hardware_source-autostem-rotation_rad 0.0\n",
      "metadata-hardware_source-center_x_nm 0.0\n",
      "metadata-hardware_source-center_y_nm 0.0\n",
      "metadata-hardware_source-channel_id a\n",
      "metadata-hardware_source-channel_index 0\n",
      "metadata-hardware_source-channel_name HAADF\n",
      "metadata-hardware_source-exposure 16.6898346666667\n",
      "metadata-hardware_source-fov_nm 128.0\n",
      "metadata-hardware_source-frame_index 8042\n",
      "metadata-hardware_source-hardware_source_id superscan\n",
      "metadata-hardware_source-hardware_source_name SuperScan\n",
      "metadata-hardware_source-line_time_us 16712.5\n",
      "metadata-hardware_source-pixel_time_us 15.9166666666667\n",
      "metadata-hardware_source-reference_key superscan_a\n",
      "metadata-hardware_source-rotation 0.0\n",
      "metadata-hardware_source-rotation_deg 0.0\n",
      "metadata-hardware_source-scan_id 3aece581-35d8-427e-8a2f-dd483bee59a6\n",
      "metadata-hardware_source-subscan_rotation 0.0\n",
      "metadata-hardware_source-valid_rows 1024\n",
      "metadata-hardware_source-view_id 5b286963-b603-4bb2-b519-11ee24922a69\n",
      "modified 2020-03-27T14:40:59.470684\n",
      "session_id 20200327-090400\n",
      "timezone America/New_York\n",
      "timezone_offset -0400\n",
      "title SuperScan (HAADF) 45\n",
      "type data-item\n",
      "uuid 673ebf08-5c30-48d5-9bdd-ef9f3f26356f\n",
      "version 13\n",
      "<HDF5 dataset \"SuperScan (HAADF) 45\": shape (1024, 1024), type \"<f4\">\n"
     ]
    }
   ],
   "source": [
    "for key,value in current_dataset.h5_dataset.parent['original_metadata'].attrs.items():\n",
    "    print(key, value)\n",
    "print(current_dataset.h5_dataset)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['SuperScan (HAADF) 45']>\n"
     ]
    }
   ],
   "source": [
    "print(current_channel.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Data\n",
    "\n",
    "To add another dataset that belongs to this measurement we will use the **h5_add_channel** from  **file_tools** in the  pyTEMlib package.\n",
    "\n",
    "Here is how we add a channel there.\n",
    "\n",
    "We can also add a new measurement group (add_measurement in pyTEMlib) for similar datasets.\n",
    "\n",
    "This is equivalent to making a new directory in a file structure on your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyNSID\n",
    "\n",
    "def add_dataset(dataset, h5_group=None):\n",
    "    \"\"\"Write data to hdf5 file\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset: sidpy.Dataset\n",
    "        data to write to file\n",
    "    h5_group: None, sidpy.Dataset, h5py.Group, h5py.Dataset, h5py.File\n",
    "        identifier to which group the data are added (if None the dataset must have a valid h5_dataset)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    h5_dataset: h5py.Dataset\n",
    "        reference the dataset has been written to. (is also stored in h5_dataset attribute of sidpy.Dataset)\n",
    "    \"\"\"\n",
    "\n",
    "    if h5_group is None:\n",
    "        if isinstance(dataset.h5_dataset, h5py.Dataset):\n",
    "            h5_group = dataset.h5_dataset.parent.parent.parent\n",
    "    if isinstance(h5_group, h5py.Dataset):\n",
    "        h5_group = h5_group.parent.parent.parent\n",
    "    elif isinstance(h5_group, sidpy.Dataset):\n",
    "        h5_group = h5_group.h5_dataset.parent.parent.parent\n",
    "    elif isinstance(h5_group, h5py.File):\n",
    "        h5_group = h5_group['Measurement_000']\n",
    "\n",
    "    if not isinstance(h5_group, h5py.Group):\n",
    "        raise TypeError('Need a valid identifier for a hdf5 group to store data in')\n",
    "\n",
    "    log_group = sidpy.hdf.prov_utils.create_indexed_group(h5_group, 'Channel_')\n",
    "    h5_dataset = pyNSID.hdf_io.write_nsid_dataset(dataset, log_group)\n",
    "\n",
    "    if hasattr(dataset, 'meta_data'):\n",
    "        if 'analysis' in dataset.meta_data:\n",
    "            log_group['analysis'] = dataset.meta_data['analysis']\n",
    "\n",
    "    dataset.h5_dataset = h5_dataset\n",
    "    return h5_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use above functions to add the content of a (random) data-file to the current file.\n",
    "\n",
    "This is important if you for example want to add a Z-contrast or survey-image to a spectrum image.\n",
    "\n",
    "Therefore, these functions enable you to collect the data from different files that belong together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Measurement_000/Channel_000\n",
      " Channel_000\n",
      "  -----------\n",
      " Channel_001\n",
      "  -----------\n",
      " Channel_002\n",
      "  -----------\n",
      "   SuperScan (HAADF) 45\n",
      "    --------------------\n",
      "     SuperScan (HAADF) 45\n",
      "     __dict__\n",
      "      --------\n",
      "     _axes\n",
      "      -----\n",
      "     _metadata\n",
      "      ---------\n",
      "     _original_metadata\n",
      "      ------------------\n",
      "     metadata\n",
      "      --------\n",
      "     original_metadata\n",
      "      -----------------\n",
      "     x\n",
      "     y\n",
      " Channel_003\n",
      "  -----------\n",
      "   SuperScan (HAADF) 45\n",
      "    --------------------\n",
      "     SuperScan (HAADF) 45\n",
      "     __dict__\n",
      "      --------\n",
      "     _axes\n",
      "      -----\n",
      "     _metadata\n",
      "      ---------\n",
      "     _original_metadata\n",
      "      ------------------\n",
      "     metadata\n",
      "      --------\n",
      "     original_metadata\n",
      "      -----------------\n",
      "     x\n",
      "     y\n",
      " SuperScan (HAADF) 45\n",
      "  --------------------\n",
      "   SuperScan (HAADF) 45\n",
      "   __dict__\n",
      "    --------\n",
      "   _axes\n",
      "    -----\n",
      "   _original_metadata\n",
      "    ------------------\n",
      "   original_metadata\n",
      "    -----------------\n",
      "   x\n",
      "   y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gduscher\\Anaconda3\\lib\\site-packages\\sidpy\\hdf\\hdf_utils.py:419: UserWarning: Casting attribute value: <HDF5 dataset \"SuperScan (HAADF) 45\": shape (1024, 1024), type \"<f4\"> of type: <class 'h5py._hl.dataset.Dataset'> to str\n",
      "  warn('Casting attribute value: {} of type: {} to str'\n",
      "C:\\Users\\gduscher\\Anaconda3\\lib\\site-packages\\sidpy\\hdf\\hdf_utils.py:419: UserWarning: Casting attribute value: <sidpy.viz.dataset_viz.ImageVisualizer object at 0x000001ACD68FE070> of type: <class 'sidpy.viz.dataset_viz.ImageVisualizer'> to str\n",
      "  warn('Casting attribute value: {} of type: {} to str'\n",
      "C:\\Users\\gduscher\\Anaconda3\\lib\\site-packages\\pyNSID\\io\\hdf_utils.py:351: FutureWarning: validate_h5_dimension may be removed in a future version\n",
      "  warn('validate_h5_dimension may be removed in a future version',\n"
     ]
    }
   ],
   "source": [
    "#new_channel = h5_add_channel(current_channel)\n",
    "add_dataset(current_dataset, current_channel.parent)\n",
    "\n",
    "ft.h5_tree(current_channel)  #wraps sidpy.hdf_utils.print_tree(h5_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding additional information\n",
    "\n",
    "Similarly, we can add a whole new measurement group or a structure group.\n",
    "\n",
    "This function will be contained in the KinsCat package of pyTEMlib.\n",
    "\n",
    "If you loaded the example image, with graphite and ZnO both are viewed in the [1,1,1] zone axis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyTEMlib.kinematic_scattering as ks         # kinematic scattering Library\n",
    "                             # with Atomic form factors from Kirkland's book\n",
    "\n",
    "def h5_add_crystal_structure(h5_file, crystal_tags):\n",
    "    structure_group = pyNSID.io.hdf_utils.create_indexed_group(h5_file,'Structure')\n",
    "    \n",
    "    structure_group['unit_cell'] = crystal_tags['unit_cell' \\\n",
    "                                                '' \\\n",
    "                                                '' \\\n",
    "                                                '']\n",
    "    structure_group['relative_positions'] = crystal_tags['base']\n",
    "    structure_group['title'] = str(crystal_tags['crystal_name'])\n",
    "    structure_group['_'+crystal_tags['crystal_name']] = str(crystal_tags['crystal_name'])\n",
    "    structure_group['elements'] = np.array(crystal_tags['elements'],dtype='S')\n",
    "    if 'zone_axis' in structure_group:\n",
    "        structure_group['zone_axis'] = np.array(crystal_tags['zone_axis'], dtype=float)\n",
    "    else:\n",
    "        structure_group['zone_axis'] = np.array([1.,1.,1.], dtype=float)\n",
    "        \n",
    "    h5_file.flush()\n",
    "    return structure_group\n",
    "\n",
    "                                                                                 \n",
    "crystal_tags = ks.structure_by_name('Graphite')\n",
    "h5_add_crystal_structure(h5_file, crystal_tags)\n",
    "                                                                                \n",
    "crystal_tags = ks.structure_by_name('ZnO')\n",
    "ft.h5_add_crystal_structure(h5_file, crystal_tags)\n",
    "\n",
    "sidpy.hdf_utils.print_tree(h5_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keeping Track of Analysis and Results\n",
    "A notebook is notorious for getting confusing, especially if one uses different notebooks for different task, but store them in the same file.\n",
    "\n",
    "If you like a result of your calculation, log it.\n",
    "|\n",
    "The function will write your calculation to the pyNSID style file and attaches a time stamp.\n",
    "\n",
    "The two functions below are part of file_tools of pyTEMlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_dictionary = {'analysis': 'Nothing', 'name': 'Nothing'}\n",
    "\n",
    "log_group = ft.log_results(current_dataset, info_dictionary)\n",
    "\n",
    "sidpy.hdf_utils.print_tree(h5_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example for a log\n",
    "We log the Fourier Transform of the image we loaded\n",
    "\n",
    "First we perform the calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Access the data of the loaded image\n",
    "data = current_dataset\n",
    "\n",
    "## The data log goes in the dictionary out_tags\n",
    "out_tags = {}\n",
    "## data tag contains the newly calculated result\n",
    "out_tags['data'] = np.fft.fftshift(np.fft.fft2(data))\n",
    "\n",
    "## meta data (can be anything, but good practice is to be compatible with pyNSID data set)\n",
    "out_tags['analysis']= 'Fourier_Transform'\n",
    "\n",
    "out_tags['spatial_origin_x'] = data.shape[0]/2\n",
    "out_tags['spatial_origin_y'] = data.shape[1]/2\n",
    "\n",
    "for dim in current_dataset.dims:\n",
    "    if dim.label == 'x': scale_x = dim[0][1]-dim[0][0]\n",
    "    if dim.label == 'y': scale_y = dim[0][1]-dim[0][0]     \n",
    "        \n",
    "out_tags['spatial_scale_x'] = 1.0/scale_x/data.shape[0]\n",
    "out_tags['spatial_scale_y'] = 1.0/scale_y/data.shape[1]\n",
    "out_tags['spatial_size_x'] = data.shape[0]\n",
    "out_tags['spatial_size_y'] = data.shape[1]\n",
    "out_tags['spatial_units'] = '1/nm'\n",
    "\n",
    "\n",
    "FOV_x = out_tags['spatial_origin_x']* scale_x\n",
    "FOV_y = out_tags['spatial_origin_y']* scale_y\n",
    "out_tags['image_extent'] = [-FOV_x,FOV_x,FOV_y, -FOV_y]\n",
    "fig = plt.figure()\n",
    "plt.imshow(np.log2(1+np.abs(out_tags['data'])),origin='upper', extent = out_tags['image_extent'])\n",
    "plt.xlabel('reciprocal distance ['+ out_tags['spatial_units']+']');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we like this we log it.\n",
    "\n",
    "Please note that just saving the fourier transform would not be good as we also need the scale and such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(ft)\n",
    "\n",
    "\n",
    "out_tags['name'] = 'fft'\n",
    "out_tags['units'] = '1/nm'\n",
    "out_tags['data_type'] = 'image'\n",
    "\n",
    "log_group = ft.log_results(current_dataset, out_tags)\n",
    "log_dataset = log_group['nDim_Data']\n",
    "ft.h5_tree(h5_file)\n",
    "fig = plt.figure()\n",
    "plt.title(log_group['analysis'][()])\n",
    "plt.imshow(np.log2(1+np.abs(log_dataset)),origin='upper', extent = log_group['image_extent'][()])\n",
    "plt.xlabel('reciprocal distance ['+ log_group['units'][()]+']');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please close the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "print(h5_file.filename)\n",
    "h5_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open h5_file\n",
    "Open the h5_file that we just created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "h5_file = ft.h5_open_file()\n",
    "\n",
    "current_channel = h5_file['Measurement_000/Channel_000']\n",
    "current_dataset = current_channel['nDim_Data']\n",
    "\n",
    "ft.h5_plot(current_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(np.array(current_dataset));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Short check if we got the data right\n",
    "we print the tree and we plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# See if a tree has been created within the hdf5 file:\n",
    "ft.h5_tree(h5_file)\n",
    "image_tags = dict(h5_file['Measurement_000/Channel_000'].attrs)\n",
    "for key in image_tags:\n",
    "    if 'original' not in key:\n",
    "        #print(key,': ',image_tags[key])\n",
    "        pass\n",
    "current_channel = h5_file['Measurement_000/Channel_000']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Add more data to this set\n",
    "\n",
    "Often more than one data set belong together.\n",
    "For instance a spectrum image has a survey image and a Z-contrast image recorded with the survey image.\n",
    "\n",
    "Here we just load another image for example *p1-3-hr3b.dm3*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "current_channel = ft.h5_add_data(current_channel)\n",
    "    \n",
    "measurement_group = current_channel.parent\n",
    "    \n",
    "for key in list(measurement_group.keys()):\n",
    "    if 'title' in measurement_group[key].keys(): \n",
    "        print(key,': ',measurement_group[key]['title'][()])\n",
    "    else:\n",
    "        print(key,': ')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Let's see what you selected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "current_dataset = current_channel['nDim_Data']\n",
    "\n",
    "ft.h5_plot(current_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## If we are done, we close the pyUID style file.\n",
    "\n",
    "This is necessary to make the file ready to be opened by another notebook or program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "h5_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navigation\n",
    "\n",
    "<font size = \"4\"> \n",
    "    \n",
    "**Back: [Matplotlib and Numpy for Micrographs](CH1_03-Data_Representation.ipynb)**<br>\n",
    "**Next: [Diffraction](CH2_00-Diffraction.ipynb)**<br>\n",
    "**Up Chapter 1: [Introduction](CH1_00-Introduction.ipynb)**<br>\n",
    "**List of Content: [Front](../_MSE672_Intro_TEM.ipynb)**\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "name": "p39",
   "language": "python",
   "display_name": "p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": "5",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}